{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lzk7iX_CodX6",
    "tags": []
   },
   "source": [
    "###### <img align=\"left\" src=\"./images/movie_camera.png\"     style=\" width:40px;  \" > Collaborative Filtering Recommender Systems\n",
    "\n",
    " Objective : Implement collaborative filtering on the MovieLens dataset to predict user ratings for movies, enhancing recommendation accuracy and user satisfaction, culminating in a functional recommender system for personalized movie suggestions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Packages \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Notation used \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. $r(i,j)$: Binary indicator that is set to 1 if user $j$ rated movie $i$.  \n",
    "   \n",
    "2. $y(i,j)$: Rating given by user $j$ for movie $i$  \n",
    "\n",
    "3. $\\mathbf{w}^{(j)}$: Parameter vector for user $j$.  \n",
    "\n",
    "4. $b^{(j)}$: Bias parameter for user $j$.  \n",
    "\n",
    "5. $\\mathbf{x}^{(i)}$: Feature vector for movie $i$.  \n",
    "\n",
    "6. $n_u$:   Number of users.  \n",
    "\n",
    "7. $n_m$: Number of movies.  \n",
    "\n",
    "8. $n$: Number of features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2 - Collaborative Filtering \n",
    "\n",
    "\n",
    " **Objective**:\n",
    "   - The goal is to recommend movies to users based on their preferences. For this purpose, two vectors are required.\n",
    "\n",
    " **Vectors**:\n",
    "   - Two types of vectors are involved:\n",
    "     - Parameter vectors for users: Represent users' movie tastes.\n",
    "     - Feature vectors for movies: Describe movie characteristics.\n",
    "   - The next question is, after obtaining parameters, how do you predict?\n",
    "\n",
    " **Dot Product**:\n",
    "   - Taking the dot product of a user's parameter vector and a movie's feature vector, along with a bias term, helps estimate how much a user might like a movie.\n",
    "\n",
    " **Estimation**:\n",
    "   - This estimation provides a prediction of the rating a user might give to a particular movie.\n",
    "\n",
    " **Personalization**:\n",
    "   - Collaborative filtering allows for personalized movie recommendations by understanding both user preferences and movie attributes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "   <img src=\"./images/ColabFilter.PNG\"  style=\"width:740px;height:350px;\" >\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **User-Item Interface Matrix**: \n",
    "  - The matrix contains ratings given by users to movies. \n",
    "  - Users are represented by rows, and movies are represented by columns.\n",
    "  - Ratings range from 0 to 10, with -1 indicating that the movie has not been rated by the user.\n",
    "\n",
    "\n",
    "\n",
    " **Parameter Vectors for Users ($\\mathbf{w}^{\\text{user}}$) and Bias**:\n",
    "  - Each user has associated parameter vectors and a bias term.\n",
    "  - These parameters represent the preferences and tendencies of each user towards different movie features.\n",
    "  - The parameters are learned based on the data in each row of the user-item interface matrix.\n",
    "\n",
    " **Feature Vectors for Movies ($\\mathbf{x}^{\\text{movie}}$)**:\n",
    "  - Each movie has associated feature vectors.\n",
    "  - These vectors describe the characteristics or attributes of each movie, such as genre, cast, director, etc.\n",
    "  - The feature vectors are learned based on the data in each column of the user-item interface matrix.\n",
    "  \n",
    " **Simultaneous Learning**:\n",
    "  - The parameter vectors for users and the feature vectors for movies are learned simultaneously using the existing user-movie ratings as training data.\n",
    "  - By analyzing the patterns in the user-item interface matrix, the model adjusts the parameter and feature vectors to better predict user ratings.\n",
    "\n",
    "In summary, the user-item interface matrix contains user ratings for movies, and based on this data, the model learns parameter vectors for users and feature vectors for movies. These vectors capture user preferences and movie characteristics, respectively, and are adjusted simultaneously during the learning process to improve the accuracy of rating predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**:\n",
    "\n",
    "Once the feature vectors and parameters are learned, they're used to predict how a user might rate an unrated movie. \n",
    "For example, in the image  user-1 didn't rated movie 2, the prediction is calculated by multiplying their preferences ($\\mathbf{w}^{\\text{user}}_1$) with the movie's features ($\\mathbf{x}^{\\text{movie}}_2$), and adding their bias term ($b^{\\text{user}}_1$):\n",
    "\n",
    "$$\n",
    "\\text{Prediction}_{\\text{user-1, movie-2}} = \\mathbf{w}^{\\text{user}}_1 \\cdot \\mathbf{x}^{\\text{movie}}_2 + b^{\\text{user}}_1\n",
    "$$\n",
    "\n",
    "This gives an estimate of how user-1 might rate movie 2, based on their preferences and the movie's characteristics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6-09Hto6odYD"
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Movie ratings dataset \n",
    "The data set is derived from the [MovieLens \"ml-latest-small\"](https://grouplens.org/datasets/movielens/latest/) dataset.   \n",
    "\n",
    "Detailed description of the dataset and the matrices involved in the collaborative filtering algorithm:\n",
    "\n",
    "- The dataset contains ratings for 9000 movies by 600 users,The dataset has been reduced in size to focus on movies from the years since 2000.\n",
    "- Ratings range from 0.5 to 5 in 0.5 increments.\n",
    "- The reduced dataset has 443 users and 4778 movies.\n",
    "- Matrices $Y$ ($n_m \\times n_u$ matrix) and $R$ store the ratings and indicators, respectively.\n",
    "- Matrix $\\mathbf{X}$ contains feature vectors for movies, $\\mathbf{W}$ contains parameter vectors for users, and $\\mathbf{b}$ contains bias terms.\n",
    "$$\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "(\\mathbf{x}^{(0)})^T  \\\\\n",
    "(\\mathbf{x}^{(1)})^T  \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{x}^{(n_m-1)})^T \\\\\n",
    "\\end{bmatrix} , \\quad\n",
    "\\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "(\\mathbf{w}^{(0)})^T \\\\\n",
    "(\\mathbf{w}^{(1)})^T \\\\\n",
    "\\vdots \\\\\n",
    "(\\mathbf{w}^{(n_u-1)})^T \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{ b} = \n",
    "\\begin{bmatrix}\n",
    " b^{(0)}  \\\\\n",
    " b^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "b^{(n_u-1)} \\\\\n",
    "\\end{bmatrix}\\quad\n",
    "$$ \n",
    "- Each feature vector $\\mathbf{x}^{(i)}$ and parameter vector $\\mathbf{w}^{(j)}$ has 10 elements.\n",
    "- $\\mathbf{X}$ is a $n_m \\times 10$ matrix, and $\\mathbf{W}$ is a $n_u \\times 10$ matrix.\n",
    "- The $i$-th row of $\\mathbf{X}$ corresponds to the\n",
    "feature vector $x^{(i)}$ for the $i$-th movie, and the $j$-th row of\n",
    "$\\mathbf{W}$ corresponds to one parameter vector $\\mathbf{w}^{(j)}$, for the\n",
    "$j$-th user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y (4778, 443) R (4778, 443)\n"
     ]
    }
   ],
   "source": [
    "file = open('./data/Y.csv', 'rb')\n",
    "Y = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "file = open('./data/R.csv', 'rb')\n",
    "R = loadtxt(file,delimiter = \",\")\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1 : 3.400 / 5\n"
     ]
    }
   ],
   "source": [
    "#  From the matrix, we can compute statistics like average rating.\n",
    "tsmean =  np.mean(Y[0, R[0, :].astype(bool)])\n",
    "print(f\"Average rating for movie 1 : {tsmean:0.3f} / 5\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Collaborative filtering learning algorithm \n",
    "\n",
    "The objective is to implement the collaborative filtering learning algorithm by defining the objective function. In this algorithm, we have parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$, and bias terms $b^{(0)},...,b^{(n_u-1)}$. \n",
    "\n",
    "The model predicts the rating for movie $i$ by user $j$ as:\n",
    "\n",
    "$$\n",
    "y^{(i,j)} = \\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}\n",
    "$$\n",
    "\n",
    "Given a dataset of ratings produced by users on movies, we aim to learn the parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$, and $b^{(0)},...,b^{(n_u-1)}$ that minimize the squared error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcqg0LJWodYH"
   },
   "source": [
    "### 4.1 Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2\n",
    "{\n",
    "+\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "}$$\n",
    "For all $i$, $j$ where $r(i,j)$ equals $1$ and could be written:\n",
    "\n",
    "$$\n",
    "= \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2\n",
    "+\\text{regularization}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Compute the cost function for collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Matrix of movie feature vectors (num_movies x num_features)\n",
    "    - W: Matrix of user parameter vectors (num_users x num_features)\n",
    "    - b: Vector of user bias terms (1 x num_users)\n",
    "    - Y: Matrix of actual ratings (num_movies x num_users)\n",
    "    - R: Binary-valued indicator matrix (num_movies x num_users)\n",
    "    - lambda_: Regularization parameter\n",
    "\n",
    "    Returns:\n",
    "    - J: Scalar value representing the cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    for j in range(nu):\n",
    "        w = W[j,:]\n",
    "        b_j = b[0,j]\n",
    "        for i in range(nm):\n",
    "            x = X[i,:]\n",
    "            y = Y[i,j]\n",
    "            r = R[i,j]\n",
    "            J += r * np.square((np.dot(w,x) + b_j - y ))\n",
    "    J += (lambda_) * (np.sum(np.square(W)) + np.sum(np.square(X)))\n",
    "    J = J/2\n",
    "    \n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized Implementation**\n",
    "\n",
    "Computing the cost $J$ using vectorized implementation will enhance efficiency, as the cost function will be called frequently to update the parameters it is recommended to have vectorized implementation of cost function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def Cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Compute the cost function for collaborative filtering.\n",
    "\n",
    "    Parameters:\n",
    "    - X: Matrix of movie feature vectors (num_movies x num_features)\n",
    "    - W: Matrix of user parameter vectors (num_users x num_features)\n",
    "    - b: Vector of user bias terms (1 x num_users)\n",
    "    - Y: Matrix of actual ratings (num_movies x num_users)\n",
    "    - R: Binary-valued indicator matrix (num_movies x num_users)\n",
    "    - lambda_: Regularization parameter\n",
    "\n",
    "    Returns:\n",
    "    - J: Scalar value representing the cost\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute predicted ratings\n",
    "    predictions = tf.matmul(X, tf.transpose(W)) + b\n",
    "\n",
    "    # Compute error\n",
    "    error = (predictions - Y) * R\n",
    "\n",
    "    # Compute squared error\n",
    "    squared_error = tf.reduce_sum(error ** 2)\n",
    "\n",
    "    # Compute regularization term\n",
    "    reg_term = (lambda_ / 2) * (tf.reduce_sum(W ** 2) + tf.reduce_sum(X ** 2))\n",
    "\n",
    "    # Compute total cost\n",
    "    J = 0.5 * squared_error + reg_term\n",
    "\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilaeM8yWodYR"
   },
   "source": [
    "\n",
    "## 5 - Learning movie recommendations \n",
    "------------------------------\n",
    "\n",
    "Now we have to start training your algorithm to make movie recommendations for yourself. Starting we will Normalize The data set Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "Ynorm = Y - np.multiply(Ymean, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Initialize the parameters w,x,b and select the Adam optimizer abd intialise the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the collaborative filtering model. To learn the parameters $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of learning $w$, $b$, and $x$ simultaneously, the conventional workflow of TensorFlow's neural network package, which includes steps like `Model`, `Compile()`, `Fit()`, and `Predict()`, is not directly applicable. Instead, a custom training loop is needed.\n",
    "\n",
    "Recalling the gradient descent algorithm:\n",
    "- Iterate until convergence:\n",
    "    - Compute the forward pass.\n",
    "    - Compute the derivatives of the loss with respect to the parameters.\n",
    "    - Update the parameters using the learning rate and the computed derivatives.\n",
    "\n",
    "TensorFlow simplifies this process by automatically computing derivatives. Operations performed on TensorFlow Variables are tracked within a `tf.GradientTape()` context. Later, when `tape.gradient()` is called, it computes the gradient of the loss with respect to the tracked variables. These gradients can then be utilized to update the parameters using an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 2277677.1\n",
      "Training loss at iteration 20: 133730.1\n",
      "Training loss at iteration 40: 50353.5\n",
      "Training loss at iteration 60: 23716.7\n",
      "Training loss at iteration 80: 13069.6\n",
      "Training loss at iteration 100: 8117.9\n",
      "Training loss at iteration 120: 5554.5\n",
      "Training loss at iteration 140: 4132.4\n",
      "Training loss at iteration 160: 3304.7\n",
      "Training loss at iteration 180: 2804.6\n",
      "Training loss at iteration 200: 2492.2\n",
      "Training loss at iteration 220: 2290.9\n",
      "Training loss at iteration 240: 2157.3\n",
      "Training loss at iteration 260: 2066.1\n",
      "Training loss at iteration 280: 2001.9\n",
      "Training loss at iteration 300: 1955.4\n",
      "Training loss at iteration 320: 1920.9\n",
      "Training loss at iteration 340: 1894.6\n",
      "Training loss at iteration 360: 1874.1\n",
      "Training loss at iteration 380: 1857.9\n"
     ]
    }
   ],
   "source": [
    "iterations = 400\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlow’s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = Cost_func(X, W, b, Ynorm, R, lambda_)\n",
    "       \n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSzUL7eQodYS"
   },
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Recommendations\n",
    "\n",
    "Now we will take a new user with some ratings already given, and then we will learn parameters and then our algorithm will then make recommendations for us according to our preferences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New user ratings:\n",
      "\n",
      "Rated 5.0 for  Shrek (2001)\n",
      "Rated 5.0 for  Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Rated 2.0 for  Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Rated 5.0 for  Harry Potter and the Chamber of Secrets (2002)\n",
      "Rated 5.0 for  Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Rated 5.0 for  Lord of the Rings: The Return of the King, The (2003)\n",
      "Rated 3.0 for  Eternal Sunshine of the Spotless Mind (2004)\n",
      "Rated 5.0 for  Incredibles, The (2004)\n",
      "Rated 2.0 for  Persuasion (2007)\n",
      "Rated 5.0 for  Toy Story 3 (2010)\n",
      "Rated 3.0 for  Inception (2010)\n",
      "Rated 1.0 for  Louis Theroux: Law & Disorder (2008)\n",
      "Rated 1.0 for  Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "movieList_df = pd.read_csv('./data/small_movie_list.csv', header=0, index_col=0,  delimiter=',', quotechar='\"')\n",
    "\n",
    "\n",
    "my_ratings = np.zeros(num_movies)          \n",
    "\n",
    "\n",
    "my_ratings[2700] = 5 # Toy Story 3 (2010)\n",
    "my_ratings[2609] = 2 # Persuasion (2007)\n",
    "my_ratings[929]  = 5   # Lord of the Rings: The Return of the King, The\n",
    "my_ratings[246]  = 5   # Shrek (2001)\n",
    "my_ratings[2716] = 3   # Inception\n",
    "my_ratings[1150] = 5   # Incredibles, The (2004)\n",
    "my_ratings[382]  = 2   # Amelie (Fabuleux destin d'Amélie Poulain, Le)\n",
    "my_ratings[366]  = 5   # Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
    "my_ratings[622]  = 5   # Harry Potter and the Chamber of Secrets (2002)\n",
    "my_ratings[988]  = 3   # Eternal Sunshine of the Spotless Mind (2004)\n",
    "my_ratings[2925] = 1   # Louis Theroux: Law & Disorder (2008)\n",
    "my_ratings[2937] = 1   # Nothing to Declare (Rien à déclarer)\n",
    "my_ratings[793]  = 5   # Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
    "\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0 :\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y    = np.c_[my_ratings, Y]\n",
    "R    = np.c_[(my_ratings != 0).astype(int), R]\n",
    "Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "Ynorm = Y - np.multiply(Ymean, R)\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)\n",
    "iterations = 200\n",
    "lambda_ = 1\n",
    "for iter in range(iterations):\n",
    "     \n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = Cost_func(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction** :\n",
    "1. Computes predictions for movie ratings using collaborative filtering by multiplying movie feature vectors with user parameter vectors, adding user bias terms, and restoring the mean rating.\n",
    "\n",
    "2. Sorts the predicted ratings in descending order to identify top recommendations for movies that the user has not rated yet.\n",
    "\n",
    "3. Prints out the top recommended movies along with their predicted ratings.\n",
    "\n",
    "4. Compares the predicted ratings with the original ratings provided by the user for movies they have rated, offering a comparison between actual and predicted preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "ns266wKtodYT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting rating 4.91 for movie 'Salem's Lot (2004)\n",
      "Predicting rating 4.90 for movie Particle Fever (2013)\n",
      "Predicting rating 4.90 for movie Eva (2011)\n",
      "Predicting rating 4.89 for movie Nine Lives of Tomas Katz, The (2000)\n",
      "Predicting rating 4.89 for movie Colourful (Karafuru) (2010)\n",
      "Predicting rating 4.89 for movie Eichmann (2007)\n",
      "Predicting rating 4.89 for movie I'm the One That I Want (2000)\n",
      "Predicting rating 4.88 for movie Paper Birds (Pájaros de papel) (2010)\n",
      "Predicting rating 4.88 for movie Indignation (2016)\n",
      "Predicting rating 4.88 for movie Won't You Be My Neighbor? (2018)\n",
      "Predicting rating 4.88 for movie I Am Not Your Negro (2017)\n",
      "Predicting rating 4.88 for movie Act of Killing, The (2012)\n",
      "\n",
      "\n",
      "Original vs Predicted ratings:\n",
      "\n",
      "Original 5.0, Predicted 4.89 for Shrek (2001)\n",
      "Original 5.0, Predicted 4.89 for Harry Potter and the Sorcerer's Stone (a.k.a. Harry Potter and the Philosopher's Stone) (2001)\n",
      "Original 2.0, Predicted 2.07 for Amelie (Fabuleux destin d'Amélie Poulain, Le) (2001)\n",
      "Original 5.0, Predicted 4.91 for Harry Potter and the Chamber of Secrets (2002)\n",
      "Original 5.0, Predicted 4.88 for Pirates of the Caribbean: The Curse of the Black Pearl (2003)\n",
      "Original 5.0, Predicted 4.89 for Lord of the Rings: The Return of the King, The (2003)\n",
      "Original 3.0, Predicted 3.07 for Eternal Sunshine of the Spotless Mind (2004)\n",
      "Original 5.0, Predicted 4.87 for Incredibles, The (2004)\n",
      "Original 2.0, Predicted 2.18 for Persuasion (2007)\n",
      "Original 5.0, Predicted 4.86 for Toy Story 3 (2010)\n",
      "Original 3.0, Predicted 3.03 for Inception (2010)\n",
      "Original 1.0, Predicted 1.48 for Louis Theroux: Law & Disorder (2008)\n",
      "Original 1.0, Predicted 1.33 for Nothing to Declare (Rien à déclarer) (2010)\n"
     ]
    }
   ],
   "source": [
    "p = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "\n",
    "#restore the mean\n",
    "pm = p + Ymean\n",
    "\n",
    "my_predictions = pm[:,0]\n",
    "\n",
    "# sort predictions\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "for i in range(17):\n",
    "    j = ix[i]\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Top movies with highest average rating and also watched by minimum of 20 users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>mean rating</th>\n",
       "      <th>number of ratings</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>4.687964</td>\n",
       "      <td>4.158537</td>\n",
       "      <td>41</td>\n",
       "      <td>In Bruges (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>4.363327</td>\n",
       "      <td>4.136364</td>\n",
       "      <td>88</td>\n",
       "      <td>Inglourious Basterds (2009)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>4.894457</td>\n",
       "      <td>4.118919</td>\n",
       "      <td>185</td>\n",
       "      <td>Lord of the Rings: The Return of the King, The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>4.856552</td>\n",
       "      <td>4.109091</td>\n",
       "      <td>55</td>\n",
       "      <td>Toy Story 3 (2010)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>4.529161</td>\n",
       "      <td>4.106061</td>\n",
       "      <td>198</td>\n",
       "      <td>Lord of the Rings: The Fellowship of the Ring,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>4.364169</td>\n",
       "      <td>4.027778</td>\n",
       "      <td>36</td>\n",
       "      <td>Thank You for Smoking (2006)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>4.436876</td>\n",
       "      <td>3.989362</td>\n",
       "      <td>47</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1 (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>4.385637</td>\n",
       "      <td>3.974138</td>\n",
       "      <td>58</td>\n",
       "      <td>28 Days Later (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>4.603886</td>\n",
       "      <td>3.961832</td>\n",
       "      <td>131</td>\n",
       "      <td>Kill Bill: Vol. 1 (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>4.376377</td>\n",
       "      <td>3.940000</td>\n",
       "      <td>50</td>\n",
       "      <td>Serenity (2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.539305</td>\n",
       "      <td>3.938235</td>\n",
       "      <td>170</td>\n",
       "      <td>Gladiator (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>4.891469</td>\n",
       "      <td>3.867647</td>\n",
       "      <td>170</td>\n",
       "      <td>Shrek (2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>4.575037</td>\n",
       "      <td>3.853659</td>\n",
       "      <td>41</td>\n",
       "      <td>Star Wars: Episode VII - The Force Awakens (2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>4.869015</td>\n",
       "      <td>3.836000</td>\n",
       "      <td>125</td>\n",
       "      <td>Incredibles, The (2004)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>4.715409</td>\n",
       "      <td>3.816901</td>\n",
       "      <td>71</td>\n",
       "      <td>Harry Potter and the Goblet of Fire (2005)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>4.878424</td>\n",
       "      <td>3.778523</td>\n",
       "      <td>149</td>\n",
       "      <td>Pirates of the Caribbean: The Curse of the Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>4.402947</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>39</td>\n",
       "      <td>Forgetting Sarah Marshall (2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4.893812</td>\n",
       "      <td>3.761682</td>\n",
       "      <td>107</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (a.k.a. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>4.589471</td>\n",
       "      <td>3.688235</td>\n",
       "      <td>85</td>\n",
       "      <td>Ice Age (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>4.911815</td>\n",
       "      <td>3.598039</td>\n",
       "      <td>102</td>\n",
       "      <td>Harry Potter and the Chamber of Secrets (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>4.464440</td>\n",
       "      <td>3.401515</td>\n",
       "      <td>66</td>\n",
       "      <td>School of Rock (2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>4.469362</td>\n",
       "      <td>3.157609</td>\n",
       "      <td>92</td>\n",
       "      <td>Star Wars: Episode II - Attack of the Clones (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred  mean rating  number of ratings  \\\n",
       "2079  4.687964     4.158537                 41   \n",
       "2395  4.363327     4.136364                 88   \n",
       "929   4.894457     4.118919                185   \n",
       "2700  4.856552     4.109091                 55   \n",
       "393   4.529161     4.106061                198   \n",
       "1598  4.364169     4.027778                 36   \n",
       "2804  4.436876     3.989362                 47   \n",
       "785   4.385637     3.974138                 58   \n",
       "877   4.603886     3.961832                131   \n",
       "1431  4.376377     3.940000                 50   \n",
       "51    4.539305     3.938235                170   \n",
       "246   4.891469     3.867647                170   \n",
       "3901  4.575037     3.853659                 41   \n",
       "1150  4.869015     3.836000                125   \n",
       "1521  4.715409     3.816901                 71   \n",
       "793   4.878424     3.778523                149   \n",
       "2127  4.402947     3.769231                 39   \n",
       "366   4.893812     3.761682                107   \n",
       "445   4.589471     3.688235                 85   \n",
       "622   4.911815     3.598039                102   \n",
       "870   4.464440     3.401515                 66   \n",
       "491   4.469362     3.157609                 92   \n",
       "\n",
       "                                                  title  \n",
       "2079                                   In Bruges (2008)  \n",
       "2395                        Inglourious Basterds (2009)  \n",
       "929   Lord of the Rings: The Return of the King, The...  \n",
       "2700                                 Toy Story 3 (2010)  \n",
       "393   Lord of the Rings: The Fellowship of the Ring,...  \n",
       "1598                       Thank You for Smoking (2006)  \n",
       "2804  Harry Potter and the Deathly Hallows: Part 1 (...  \n",
       "785                                28 Days Later (2002)  \n",
       "877                            Kill Bill: Vol. 1 (2003)  \n",
       "1431                                    Serenity (2005)  \n",
       "51                                     Gladiator (2000)  \n",
       "246                                        Shrek (2001)  \n",
       "3901  Star Wars: Episode VII - The Force Awakens (2015)  \n",
       "1150                            Incredibles, The (2004)  \n",
       "1521         Harry Potter and the Goblet of Fire (2005)  \n",
       "793   Pirates of the Caribbean: The Curse of the Bla...  \n",
       "2127                   Forgetting Sarah Marshall (2008)  \n",
       "366   Harry Potter and the Sorcerer's Stone (a.k.a. ...  \n",
       "445                                      Ice Age (2002)  \n",
       "622      Harry Potter and the Chamber of Secrets (2002)  \n",
       "870                               School of Rock (2003)  \n",
       "491   Star Wars: Episode II - Attack of the Clones (...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter=(movieList_df[\"number of ratings\"] > 20)\n",
    "movieList_df[\"pred\"] = my_predictions\n",
    "movieList_df = movieList_df.reindex(columns=[\"pred\", \"mean rating\", \"number of ratings\", \"title\"])\n",
    "movieList_df.loc[ix[:300]].loc[filter].sort_values(\"mean rating\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
